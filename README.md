# ğŸ“š Scholar Graph-RAG

> **Scholar Graph-RAG** is an **AI-powered research assistant** that blends  
> ğŸ§  **Knowledge Graphs**, ğŸ“„ **arXiv papers**, and ğŸ¤– **LLMs** into one seamless tool.  
> Ask complex research questions, retrieve **grounded answers**, and explore  
> the **connections between concepts, papers, and entities** in an intuitive interface.  

---
<img width="1180" height="658" alt="image" src="https://github.com/user-attachments/assets/d8e588b4-b586-4781-b7d7-dd65c35501de" />

## âœ¨ Features

- ğŸ” **Graph-RAG Retrieval** â€“ Combines **vector search** + **graph traversal** for rich, contextual answers.  
- ğŸ’¬ **Conversational AI** â€“ Ask natural language queries and stream AI responses in real time.  
- ğŸ“Š **Interactive Graph** â€“ Visualize entities, methods, and their relationships.  
- ğŸ“‘ **Research Metadata** â€“ Instantly access paper titles, abstracts, and PDF links.  
- ğŸ•’ **History Sidebar** â€“ Revisit past conversations like in modern AI assistants.  
- âš¡ **Scalable Backend** â€“ PySpark + Neo4j + FastAPI for efficient processing and retrieval.  



---

## ğŸ› ï¸ Tech Stack  

**Backend**:  
- âš¡ FastAPI â€“ API & streaming  
- ğŸ”— Neo4j â€“ graph + vector search  
- ğŸ”¥ PySpark â€“ large-scale processing  
- ğŸ“„ PyMuPDF â€“ PDF text extraction  
- ğŸ§© LangChain + Ollama/OpenRouter â€“ embeddings + LLM  

**Frontend**:  
- âš›ï¸ React + Tailwind â€“ modern UI  
- ğŸ“ˆ D3.js (or Vis.js) â€“ graph visualization  
- ğŸ”„ SSE â€“ live streaming of LLM answers  

---

## âš¡ Quick Start  

### 1ï¸âƒ£ Clone the Repo
```bash
git clone https://github.com/YOUR-USERNAME/ScholarAI-Graph-Rag.git
cd ScholarAI-Graph-Rag

```
### 2ï¸âƒ£ Backend Setup
```
cd backend
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt

uvicorn main:app --reload --host 0.0.0.0 --port 8000

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=yourpassword
NEO4J_DATABASE=neo4j

LLM_PROVIDER=openrouter   # or ollama
EMBED_MODEL=nomic-embed-text
GEN_MODEL= CHOSE YOUR MODEL (EG: OPENAI OSS) ```
```
### 3ï¸âƒ£ Frontend Setup
```
cd frontend
npm install
npm run dev
```


